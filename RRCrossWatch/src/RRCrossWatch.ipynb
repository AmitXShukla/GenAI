{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RRCrossWatch.ai\n",
    "---\n",
    "`Claude GenAI App - An automated vision AI, which watches Railroad Crossing for potential Hazard`\n",
    "\n",
    "TODO: - Was working on this several years now, and it's too expensive to collect such images data and train neural network on it. Training is very expensive and my models just couldn't beat Claude or Open AI Image models\n",
    "\n",
    "The objective is to develop an AI capable of identifying objects based on input images and classify / tag Rail road crossing or any place else where crowd or hazard object close monitoring is required.\n",
    "\n",
    "**Author:** Amit Shukla\n",
    "\n",
    "**Connect**\n",
    "Author: Amit Shukla\n",
    "\n",
    "[https://github.com/AmitXShukla](https://github.com/AmitXShukla)\n",
    "\n",
    "[https://x.com/ashuklax](https://x.com/AShuklaX)\n",
    "\n",
    "[https://youtube.com/@Amit.Shukla](https://youtube.com/@Amit.Shukla)\n",
    "\n",
    "---\n",
    "\n",
    "In this blog, we will create an online manual for Python, Oracle or Julia Lang, Angular and Flutter.\n",
    "\n",
    "**Step 0:** getting started\n",
    "\n",
    "**Step 1:** build a simple web crawler - Scrapify\n",
    "    \n",
    "In this section, we will\n",
    "\n",
    "1. query LLM API and build a Q&A from LLM.\n",
    "2. read data from PDF files and then query LLM.\n",
    "3. Scape an online page and query LLM.\n",
    "4. automated crawling: build a simple `web crawler` to gather text from the website. The crawler will collect links from the given domain and then visit each link to download the associated text. \n",
    "5. explore various options for downloading data from Single Page Applications (SPAs) using web scraping techniques and libraries such as BeautifulSoup, Scrapy, and Selenium.\n",
    "6. Image data extraction:\n",
    "look into different methods for extracting data from images, including Optical Character Recognition (OCR) techniques and libraries such as Tesseract.\n",
    "7. read data from PDF files: Additionally, we will examine ways to read and extract data from PDF files using libraries such as PyPDF2 and PDFMiner.\n",
    "8. Querying Language Models (LLMs):\n",
    "Once we have extracted the data, we will then query the Language Models (LLMs) with the extracted data to generate insights and answers.\n",
    "\n",
    "**Step 2:** We will convert all PDFs to csv and simply build a Q&A prompt using Gen AI (Claude) with entire file content at once.\n",
    "\n",
    "**Step 3:** Creating Embedding from csvs and other documents to create a Vector database.\n",
    "\n",
    "**Step 4:** Using RAG and LLMs to query manual documments.\n",
    "\n",
    "**Step 5:** Using SQL queries with Functional calling.\n",
    "\n",
    "**Step 6:** creating an online app and hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
