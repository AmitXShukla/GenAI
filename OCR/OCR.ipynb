{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build, host and serve a 100% local OCR Vision AI using open source technologies\n",
    "\n",
    "## Objective\n",
    "build a 100% Local OCR Vision AI using open source code with complete automated workflow.\n",
    "\n",
    "## What you'll learn\n",
    "Hands on experience to build Gen AI RAG based Pro App, running 100% locally/hosted or API based, using API / open source tools.\n",
    "\n",
    "## Tools\n",
    "\n",
    "\tProgamming: Python 3.12+\n",
    "\tLLM: Gemini or llama 3.2 or OpenAI ChatGPT or Anthropic\n",
    "    Embeddings: mxbai-embed-larg or any embedding model\n",
    "\tVector DB: ChromaDB or SQLLite or any VectorDB of your choice\n",
    "\tGUI App: Taipy or Open WebUI or Flutter\n",
    "\tIDE: Jupyter Lab\n",
    "    OCR: Tesseract or PyPDF or Oracle or Azure Document Services or any API based vision AI\n",
    "\n",
    "## Next Steps\n",
    "\tAgents based framework implementation, Enterprise ready\n",
    "\t- Langchain | LangGraphs or\n",
    "\t- swarms or\n",
    "\t- crewAI or\n",
    "\t- Microsoft Autogen | Semantics Kernels\n",
    "\n",
    "\n",
    "## Disclaimer\n",
    "In this blog post, I will demonstrate one automation use case I have been working on.\n",
    "\n",
    "It's important to note that these use cases/models will work best when trained on \"in-house\" data. However, training such models is a rigorous task that requires significant computing hours and resources.\n",
    "  \n",
    "To make things more accessible and easier to utilize in production, using \"off the shelf\", language models like ChatGPT and Llama 3.2 is a viable solution.\n",
    "\n",
    "*While these examples are not meant for production*, they still showcase the powerful capabilities of the language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "stateDiagram-v2\n",
    "        direction LRstateDiagram-v2\n",
    "        [*] --> User_Query\n",
    "        User_Query --> Conversation_AI_Agent\n",
    "        Conversation_AI_Agent --> SQL_DB\n",
    "        SQL_DB --> Conversation_AI_Agent\n",
    "        Conversation_AI_Agent --> RAG_VectorDB\n",
    "        RAG_VectorDB --> Conversation_AI_Agent\n",
    "        [*] --> File_Drop\n",
    "        File_Drop --> PyPDF\n",
    "        File_Drop --> Tesseract\n",
    "        File_Drop --> AzureDocementService\n",
    "        File_Drop --> OracleVisionAI\n",
    "        File_Drop --> OtherVisionAPI\n",
    "        PyPDF --> QC\n",
    "        Tesseract --> QC\n",
    "        AzureDocementService --> QC\n",
    "        OracleVisionAI --> QC\n",
    "        OtherVisionAPI --> QC\n",
    "        QC --> QC_AI_Agent\n",
    "        QC_AI_Agent --> QC\n",
    "        QC_AI_Agent --> RAG_VectorDB\n",
    "        QC_AI_Agent --> SQL_DB\n",
    "        QC_AI_Agent --> [*]\n",
    "        Conversation_AI_Agent --> [*]\n",
    "\n",
    "%% Define classes for coloring\n",
    "    classDef red fill:#ff8,stroke:#333,stroke-width:2px;\n",
    "    classDef green fill:#8fa,stroke:#333,stroke-width:2px;\n",
    "    classDef blue fill:#8af,stroke:#333,stroke-width:2px;\n",
    "    classDef orange fill:#f92,stroke:#333,stroke-width:2px;\n",
    "    classDef brown fill:#e6f,stroke:#333,stroke-width:2px;\n",
    "    classDef neil fill:#1ff,stroke:#333,stroke-width:2px;\n",
    "\n",
    "    %% Apply classes to states\n",
    "    class User_Query green\n",
    "    class Conversation_AI_Agent orange\n",
    "    class social green\n",
    "    class Tesseract brown\n",
    "    class SQL_DB blue\n",
    "    class File_Drop green\n",
    "    class RAG_VectorDB blue\n",
    "    class PyPDF brown\n",
    "    class QC_AI_Agent orange\n",
    "    class QC red\n",
    "    class AzureDocementService brown\n",
    "    class OracleVisionAI brown\n",
    "    class OtherVisionAPI brown\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate AI on File Drop - Setup CRON job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Shell Script: OCR_script.sh\n",
    "# create a shell script that will check for the file and execute the Python script when the file is found.\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "WATCHED_DIR=\"/path/to/watched/directory\"\n",
    "FILE_NAME=\"yourfile.txt\"\n",
    "PYTHON_SCRIPT=\"/path/to/your/OCR_Agent.py\"\n",
    "\n",
    "if [ -f \"$WATCHED_DIR/$FILE_NAME\" ]; then\n",
    "    python3 $PYTHON_SCRIPT\n",
    "    # Optionally, move or delete the file after processing\n",
    "    mv \"$WATCHED_DIR/$FILE_NAME\" \"$WATCHED_DIR/processed/\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the Shell Script Executable:\n",
    "# $ chmod +x /path/to/your/OCR_script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up the Cron Job: Open the crontab editor:\n",
    "# $ crontab -e\n",
    "\n",
    "# add this line to crontab\n",
    "# * * * * * /path/to/your/OCR_script.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR_Agent.py\n",
    "with open(\"/path/to/output/file.txt\", \"w\") as f:\n",
    "    f.write(\"File has been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR - read file content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf\n",
    "# !curl -O https://github.com/AmitXShukla/RPA/blob/main/SampleData/The%20Ultimate%20Guide%20to%20Data%20Wrangling%20with%20Python%20-%20Rust%20Polars%20Data%20Frame.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"../downloads/Python - understanding functions.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "text = ''.join([page.extract_text() for page in reader.pages])\n",
    "print(text[:2155])\n",
    "\n",
    "import ollama\n",
    "\n",
    "data =\"\"\n",
    "prompt = \"how are args and kwargs different in python\"\n",
    "import ollama\n",
    "\n",
    "def get_completion(prompt):\n",
    "    output = ollama.generate(\n",
    "        model=\"llama3.1\",\n",
    "        prompt=f\"\"\"answer this question : {prompt}\"\"\"\n",
    "        )\n",
    "    return output[\"response\"]  # type: ignore\n",
    "\n",
    "completion = get_completion(\n",
    "    f\"\"\"Here is a local guide: <guide>{text}</guide>    \n",
    "\n",
    "Please do the following:\n",
    "1. Summarize the abstract about Python args \n",
    "and keyword args understanding at a kindergarten reading level. (In <kindergarten_abstract> tags.)\n",
    "2. Write the Methods section as a recipe from the Moosewood Cookbook. (In <moosewood_methods> tags.)\n",
    "\"\"\"\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read text from images using Tesseract OCR in Python, we can use the pytesseract library, which is a Python wrapper for the Tesseract OCR engine. Here's an example code snippet:\n",
    "\n",
    "[download tesseract here](https://tesseract-ocr.github.io/tessdoc/#binaries)\n",
    "\n",
    "`Note that Tesseract OCR is not perfect and may not be able to extract text accurately from all images.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py -m pip install pytesseract PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('../downloads/AAPL.png')\n",
    "img.show()\n",
    "\n",
    "# make sure, you have tesseract included in your environment path\n",
    "\n",
    "import os\n",
    "os.getenv(\"tesseract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "##############################################################################\n",
    "# in case if tesseract is not included in PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\amit.la\\WIP\\RPA\\downloads\\ts\\tesseract.exe'\n",
    "##############################################################################\n",
    "\n",
    "def read_image_text(image_path):\n",
    "    \"\"\"\n",
    "    Reads text from an image file using Tesseract OCR.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text from the image.\n",
    "    \"\"\"\n",
    "    # Load the image file\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Use Tesseract OCR to extract the text from the image\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "image_path = \"../downloads/APPL.png\"\n",
    "text = read_image_text(image_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {\n",
    "        \"AAPL\": \"../downloads/AAPL.png\",\n",
    "        \"ORCL\": \"../downloads/ORCL.png\",\n",
    "        \"TSLA\": \"../downloads/TSLA.png\",\n",
    "        \"GOOG\": \"../downloads/GOOG.png\",\n",
    "        \"MSFT\": \"../downloads/MSFT.png\"\n",
    "    }\n",
    "\n",
    "# automate reading images and creating text from these images\n",
    "# you can further store these texts into a database\n",
    "\n",
    "for key,value in images.items():\n",
    "    # print(key, value)\n",
    "    text = read_image_text(value)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: using Microsoft Document Services API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code sample shows Prebuilt Read operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Form Recognizer Python client library SDKs\n",
    "https://learn.microsoft.com/azure/applied-ai-services/form-recognizer/quickstarts/get-started-v3-sdk-rest-api?view=doc-intel-3.1.0&pivots=programming-language-python\n",
    "\"\"\"\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "endpoint = \"YOUR_FORM_RECOGNIZER_ENDPOINT\"\n",
    "key = \"YOUR_FORM_RECOGNIZER_KEY\"\n",
    "\n",
    "def format_bounding_box(bounding_box):\n",
    "    if not bounding_box:\n",
    "        return \"N/A\"\n",
    "    return \", \".join([\"[{}, {}]\".format(p.x, p.y) for p in bounding_box])\n",
    "\n",
    "def analyze_read():\n",
    "    # sample document\n",
    "    formUrl = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/sample-layout.pdf\"\n",
    "\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "    \n",
    "    poller = document_analysis_client.begin_analyze_document_from_url(\n",
    "            \"prebuilt-read\", formUrl)\n",
    "    result = poller.result()\n",
    "\n",
    "    print (\"Document contains content: \", result.content)\n",
    "    \n",
    "    for idx, style in enumerate(result.styles):\n",
    "        print(\n",
    "            \"Document contains {} content\".format(\n",
    "                \"handwritten\" if style.is_handwritten else \"no handwritten\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for page in result.pages:\n",
    "        print(\"----Analyzing Read from page #{}----\".format(page.page_number))\n",
    "        print(\n",
    "            \"Page has width: {} and height: {}, measured with unit: {}\".format(\n",
    "                page.width, page.height, page.unit\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for line_idx, line in enumerate(page.lines):\n",
    "            print(\n",
    "                \"...Line # {} has text content '{}' within bounding box '{}'\".format(\n",
    "                    line_idx,\n",
    "                    line.content,\n",
    "                    format_bounding_box(line.polygon),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for word in page.words:\n",
    "            print(\n",
    "                \"...Word '{}' has a confidence of {}\".format(\n",
    "                    word.content, word.confidence\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 4: using Oracle Vision API\n",
    "## Approach 5: using Other Vision API\n",
    "## Approach 6*: future - using ollama llama3.2 multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Agent to validate OCR Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to implement a more sophisticated agent-based framework to create an Enterprise QC Agents interface. \n",
    "We'll revisit this topic in future blogs, where we'll explore agents in greater detail.\n",
    "\n",
    "\tAgents based framework implementation, Enterprise ready\n",
    "\t- Langchain | LangGraphs or\n",
    "\t- swarms or\n",
    "\t- crewAI or\n",
    "\t- Microsoft Autogen | Semantics Kernels\n",
    "\n",
    "For the time being, we'll utilize a straightforward GenAI Chat interface to share content and evaluate whether the LLM model considers it valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "data = \"\" # data read from OCR\n",
    "\n",
    "def get_completion(prompt):\n",
    "    output = ollama.generate(\n",
    "        model = \"llama3.2\",\n",
    "        prompt = prompt\n",
    "        )\n",
    "    return output[\"response\"]  # type: ignore\n",
    "\n",
    "completion = get_completion(\n",
    "    f\"\"\"Here is a local input: <guide>{data}</guide>\n",
    "\n",
    "Please do the following:\n",
    "Local input is being received from an OCR reader, and I want to assess whether this data appears to be a reasonable extract from a document.\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push data to SQL DB and RAG Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database (or create it)\n",
    "conn = sqlite3.connect('example.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    age INTEGER\n",
    ")\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "# Insert a record\n",
    "cursor.execute('''\n",
    "INSERT INTO users (name, age) VALUES (?, ?)\n",
    "''', ('Alice Wonder', 30))\n",
    "conn.commit()\n",
    "\n",
    "# Retrieve records\n",
    "cursor.execute('SELECT * FROM users')\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('example.db')\n",
    "cursor = conn.cursor()\n",
    "def get_user(employee):\n",
    "  # Insert a record\n",
    "  # cursor.execute('''\n",
    "  # INSERT INTO users (name, age) VALUES (?, ?)\n",
    "  # ''', ('Alice Wonder', 30))\n",
    "  # conn.commit()\n",
    "  print(f\"SELECT * FROM users where name = {employee}\")\n",
    "  cursor.execute(f\"SELECT * FROM users where name = '{employee}'\")\n",
    "  rows = cursor.fetchall()\n",
    "  # for row in rows:\n",
    "  #   print(row)\n",
    "  return rows\n",
    "\n",
    "print(get_user(\"Alice\"))\n",
    "\n",
    "# Close the connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create Chat with Tools/Function calling to query SQL and RAG DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "tools = [{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "    {\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_user',\n",
    "        'description': 'Get the current age of employee',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'employee': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the employee',\n",
    "            },\n",
    "          },\n",
    "          'required': ['employee'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ]\n",
    "\n",
    "# creating a generic function to call appropriate tool based on tool input\n",
    "def process_tool_call(tool_name, tool_input):\n",
    "    if tool_name == \"get_current_weather\":\n",
    "        return get_current_weather(tool_input[\"city\"])\n",
    "    if tool_name == \"get_user\":\n",
    "        return get_user(tool_input[\"employee\"])\n",
    "  \n",
    "# print(process_tool_call('get_current_weather', {'city': 'Los Angeles CA'}))\n",
    "print(process_tool_call('get_user', {'employee': 'Alice'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[{'role': 'user', 'content': \n",
    "            'how old is Alice?'}],\n",
    "\t\t    # provide a weather checking tool to the model\n",
    "        tools=tools # type: ignore\n",
    "    )\n",
    "\n",
    "# response \n",
    "print(f\"\\nInitial Response:\")\n",
    "print(f\"Tool called: {response[\"message\"][\"tool_calls\"][0]}\")\n",
    "print(f\"Tool name: {response[\"message\"][\"tool_calls\"][0][\"function\"][\"name\"]}\")\n",
    "print(f\"Tool param: {response[\"message\"][\"tool_calls\"][0][\"function\"][\"arguments\"]}\")\n",
    "print(f\"Stop Reason: {response[\"done_reason\"]}\")\n",
    "print(f\"Content: {response[\"message\"][\"content\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[{'role': 'user', 'content': \n",
    "            'What is the weather in Los Angeles CA today?'}],\n",
    "\t\t    # provide a weather checking tool to the model\n",
    "        tools=tools # type: ignore\n",
    "    )\n",
    "\n",
    "# response \n",
    "print(f\"\\nInitial Response:\")\n",
    "print(f\"Tool called: {response[\"message\"][\"tool_calls\"][0]}\")\n",
    "print(f\"Tool name: {response[\"message\"][\"tool_calls\"][0][\"function\"][\"name\"]}\")\n",
    "print(f\"Tool param: {response[\"message\"][\"tool_calls\"][0][\"function\"][\"arguments\"]}\")\n",
    "print(f\"Stop Reason: {response[\"done_reason\"]}\")\n",
    "print(f\"Content: {response[\"message\"][\"content\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatBot(user_message):\n",
    "    print(f\"\\n{'='*50}\\nUser Message: {user_message}\\n{'='*50}\")\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[{'role': 'user', 'content': user_message}],\n",
    "\t\t    # provide a weather checking tool to the model\n",
    "        tools=tools # type: ignore\n",
    "    )\n",
    "    print(f\"\\nInitial Response:\")\n",
    "    print(f\"Tool called: {response[\"message\"][\"tool_calls\"][0]}\")\n",
    "    print(f\"Stop Reason: {response[\"done_reason\"]}\")\n",
    "    print(f\"Content: {response[\"message\"][\"content\"]}\")\n",
    "\n",
    "    if response[\"done_reason\"] == \"stop\":\n",
    "        # tool_use = next(block for block in response.content if block.type == \"tool_use\")\n",
    "        tool_name = response[\"message\"][\"tool_calls\"][0][\"function\"][\"name\"]\n",
    "        tool_input = response[\"message\"][\"tool_calls\"][0][\"function\"][\"arguments\"]\n",
    "        tool_content = response[\"message\"][\"content\"]\n",
    "\n",
    "        tool_result = process_tool_call(tool_name, tool_input)\n",
    "        print(f\"Tool Result: {tool_result}\")\n",
    "\n",
    "        response = ollama.chat(\n",
    "                model='llama3.2',\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_message},\n",
    "                    # {\"role\": \"assistant\", \"content\": f\"as per results from tools API, current data is {str(tool_result)} , based on this data, please answer this {user_message}.\"},\n",
    "                    {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": str(tool_result) # type: ignore\n",
    "                    },\n",
    "                ],\n",
    "                tools=tools # type: ignore\n",
    "                )\n",
    "        print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatBot(\"How is the weather in San Francisco today?\")\n",
    "# chatBot(\"How old is my employee name Alice?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a Chat APP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build, host, serve GenAI RAG app using llama3.2, ollama, ChromaDB SQLite, Taipy, openwebui\n",
    "\n",
    "please visit this [X-Article](https://x.com/ashuklax/status/1854404956075217330) or visit this youtube [tutorial](https://www.youtube.com/playlist?list=PLp0TENYyY8lF8EsgtfDoPkuAgxc-lcwbd)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
