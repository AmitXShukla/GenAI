{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NWCarCasing.ai\n",
    "---\n",
    "`Claude GenAI App - Neighborhood watch car casing`\n",
    "\n",
    "TODO: - Tenants license plate information in app as well\n",
    "\n",
    "`NWCarCasing.ai:` A Vision-Based AI System: Automated Identification and Tagging of Non-Neighborhood Vehicles Exhibiting Suspicious Behavior.\n",
    "\n",
    "The objective is to develop an AI capable of identifying car based on input images and classify / tag car if car doesn't belong to any tenants in neighborhood.\n",
    "\n",
    "**Author:** Amit Shukla\n",
    "\n",
    "**Connect**\n",
    "Author: Amit Shukla\n",
    "\n",
    "[https://github.com/AmitXShukla](https://github.com/AmitXShukla)\n",
    "\n",
    "[https://x.com/ashuklax](https://x.com/AShuklaX)\n",
    "\n",
    "[https://youtube.com/@Amit.Shukla](https://youtube.com/@Amit.Shukla)\n",
    "\n",
    "---\n",
    "\n",
    "In this blog, we will create an online manual for Python, Oracle or Julia Lang, Angular and Flutter.\n",
    "\n",
    "**Step 0:** getting started\n",
    "\n",
    "**Step 1:** build a simple web crawler - Scrapify\n",
    "    \n",
    "In this section, we will\n",
    "\n",
    "1. query LLM API and build a Q&A from LLM.\n",
    "2. read data from PDF files and then query LLM.\n",
    "3. Scape an online page and query LLM.\n",
    "4. automated crawling: build a simple `web crawler` to gather text from the website. The crawler will collect links from the given domain and then visit each link to download the associated text. \n",
    "5. explore various options for downloading data from Single Page Applications (SPAs) using web scraping techniques and libraries such as BeautifulSoup, Scrapy, and Selenium.\n",
    "6. Image data extraction:\n",
    "look into different methods for extracting data from images, including Optical Character Recognition (OCR) techniques and libraries such as Tesseract.\n",
    "7. read data from PDF files: Additionally, we will examine ways to read and extract data from PDF files using libraries such as PyPDF2 and PDFMiner.\n",
    "8. Querying Language Models (LLMs):\n",
    "Once we have extracted the data, we will then query the Language Models (LLMs) with the extracted data to generate insights and answers.\n",
    "\n",
    "**Step 2:** We will convert all PDFs to csv and simply build a Q&A prompt using Gen AI (Claude) with entire file content at once.\n",
    "\n",
    "**Step 3:** Creating Embedding from csvs and other documents to create a Vector database.\n",
    "\n",
    "**Step 4:** Using RAG and LLMs to query manual documments.\n",
    "\n",
    "**Step 5:** Using SQL queries with Functional calling.\n",
    "\n",
    "**Step 6:** creating an online app and hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
